---
title: "R Notebook"
output:
  pdf_document: default
  html_document:
    df_print: paged
  html_notebook: default
---

## Exercise 1. Ice Cream

**a)**
```{r, fig.height=2.6, fig.width=6}
#Read in the data and extract the relevant column
ice_cream=read.csv("data/Ice_cream.csv",header=TRUE) 
video=ice_cream$video

#Create relevant figures to assess distribution normality
par(mfrow=c(1,3))
hist(video, xlab="Video Game Scores", main="Scores Histogram"); 
boxplot(video, ylab="Video Game Scores", main="Scores Boxplot"); 
qqnorm(video, main="Video Scores Q-Q Plot")
```

The data for the video games scores appears to be close to normally distributed. Both the histogram and boxplot indicate that the scores are unimodal and moderately evenly distributed about the mean. The qq-plot confirms this as the data points are nearly linear. Hence, any testing or methods used with a normality assumption are justified.

```{r}
#Constructing a bounded 97% confidence interval 
video_mean = mean(video)
video_se = sd(video)/sqrt(length(video))
alpha = 0.03
degrees_freedom = length(video) - 1
t_score = qt(p=alpha/2, df=degrees_freedom, lower.tail=F)
margin_error = video_se * t_score
lower_bound = video_mean - margin_error
upper_bound = video_mean + margin_error
```

The bounds for the 97% confidence interval are [`r round(lower_bound, 4)`, `r round(upper_bound, 4)`].

```{r}
#Calculating the number of samples needed for a confidence interval of at most length 3
desired_margin_error = 1.5
z_score = qnorm(0.985)
num_samples = ((z_score*sd(video))/desired_margin_error)^2
```

The number of samples needed for a confidence interval of at most length 3 is at least `r ceiling(num_samples)`.

```{r}
#Creating a bootstrapped 97% confidence interval
B = 1000
Tstar = numeric(B)
for (i in 1:B) {
  Xstar = sample(video, replace = TRUE) 
  Tstar[i] = mean(Xstar)
}
Tstar015 = quantile(Tstar, 0.015)  #Lower bound
Tstar985 = quantile(Tstar, 0.985)  #Upper bound

confidence_interval = c(2*mean(video) - Tstar985, 2*mean(video) - Tstar015)
```

Our bootstrapped confidence interval is (`r round(confidence_interval[[1]], 4)`, `r round(confidence_interval[[2]], 4)`). We notice that this confidence interval is minutely smaller than the bounded confidence interval above. However, they are extremely similar. Since the data is already relatively normally distributed, the original confidence interval likely provides a good enough estimate and bootstrapping is unnecessary in this case.

**b)**
```{r}
#First t-test when mu_0 = 50
t.test(video, mu=50, alt="g")

#Second t-test when mu_0 = 51
t.test(video, mu=51, alt="g")
```

Since the p-value for the first one-sided t-test when $\mu_{0}$ = 50 is less than 0.05, we would reject the null hypothesis that the mean video game score for the sample is equal to 50 in favor of the alternative hypothesis that it is greater than 50. Since we are doing a right-sided t-test, we have a confidence interval that extends to the left of the mean by the standard error amount, but to the right to infinity, since we do not actually specify or care what the upper bound is for the mean, as long as it is greater than 50. In the second case, we have the same case with regard to the confidence interval. However, our t-statistic and p-value have changed. In the calculation of the t-value, we subtract $\mu$ from our calculated mean. When t differs greatly from 0, our p-value will be larger. In this case, our p-value is greater than 0.05, so we do not reject the null hypothesis that the mean is equal to 51. We also notice that our actual mean is closer to 51 than it is to 50, so intuitively we would expect that we're more likely to accept the alternative hypothesis that the mean is larger than 50 than the alternative that the mean is larger than 51. 

**c)**
```{r}
binom.test(sum(video>50), length(video), p=0.5, alt="g")

wilcox.test(video, mu=50, alt="g")

binom.test(sum(video<42), length(video), p=0.25, alt="l")
```

First, we conduct a sign test to determine whether or not the median is greater than 50. Our null hypothesis is that the median is less than or equal to fifty, while our alternative hypothesis is that it is greater than 50. Since our resulting p-value is greater than 0.05, we do not reject the null hypothesis that the median is less than or equal to 50. This test does not align with out result from part b); however, in this case we are comparing medians and not means. In particular, with the sign test, we are not comparing the actual data values. Therefore, t-test is more sensitive to smaller deviations from the mean and any slight skewness. 

Secondly, we conduct a Wilcoxon signed rank test. Since our data is close to normal, we fulfill the requirement of a symmetric distribution. We follow the same hypotheses as the sign test above. However, since our p-value is much less than 0.05, we reject the null hypothesis in favor of the alternative.

To perform a test to check whether the fraction of the scores less than 42 is at most 25%, we can do a modified version of the sign test for medians, but instead compare the lower quartiles. In this case, we have a null hypothesis that the lower quartile is greater than or equal to 42 and an alternative hypothesis that it is less than or equal to 42. Since our p-value is much lower than 0.05, we reject the null hypothesis in favor of the alternative that in fact the fraction of scores less than 42 is at most 25%.

**d)**
```{r}
n=length(video)
t=min(video)
mus = c()
B=1000; tstar=numeric(B)
for (j in 0:100){
  for (i in 1:B){
  xstar=rnorm(200, mean=j, sd=10)
  tstar[i]=min(xstar)
  }
  pl=sum(tstar<t)/B; pr=sum(tstar>t)/B
  p=2*min(pl,pr)
  if (p >= 0.05){
    mus = c(mus, j)
  }
}
```

The values of $\mu$ for which the null hypothesis is not rejected are `r mus`.

```{r}
ks_mus = c()
suppressWarnings(for (j in 0:100){
  xstar=rnorm(200, mean=j, sd=10)
  p = ks.test(video, xstar)[[2]]
  if (p >= 0.05){
    ks_mus = c(ks_mus, j)
  }
})
```

The Kolmogorov-Smirnov test is applicable in this case since we have two independent samples: one from our dataset and one from our simulated normal distribution. In this case, we can conduct an experiment similar to that above. By using a Kolmogorov-Smirnov test, the values of $\mu$ for which the null hypothesis is not rejected are `r ks_mus`.

**e)**
```{r, fig.height=2.6, fig.width=6}
#Extracting the boolean data for scores from women and men
women_scores = ice_cream$video[ice_cream$female == 1]
men_scores = ice_cream$video[ice_cream$female == 0]

par(mfrow=c(1,2))
qqnorm(women_scores, main="Women's Scores Q-Q Plot"); qqnorm(men_scores, main="Men's Scores Q-Q Plot")

#Two-sample t-test
t.test(women_scores, men_scores)
```

In order to conduct a two-sample t-test, we assume independence in our samples. In this case that is applicable, since we assume each player plays the game without confounding factors. We also assume normality in the data. According to our qq-plots, we see that the data points are almost linear, so we can carefully make this assumption. The results of the t-test indicate a p-value that is greater than 0.05, so we do not reject the null hypothesis that the mean values of the video game scores for men and women are different.

```{r}
#Mann-Whitney test
wilcox.test(women_scores, men_scores)

#Kolmogorov-Smirnov test
ks.test(women_scores, men_scores)
```

Similarly, the Mann-Whitney and Kolmogorov Smirnov tests assume independence of samples. In this case, both of these are applicable. In both cases, we find p-values that are greater than 0.05. For these tests, we do not reject the null hypothesis that the underlying distributions of these samples are different. In this case, the permutation test is not applicable because that requires paired samples, which these are not.

**f)**
```{r, fig.height=2.6, fig.width=3}
puzzle=ice_cream$puzzle

#Check normality for the puzzle scores
qqnorm(puzzle, main="Puzzle Scores Q-Q Plot")
cor.test(video, puzzle, method="spearman")
```

To use Pearson's correlation test, we need to first check the normality assumption for the puzzle score data, since we have already checked the assumption for the video game score data. The data looks more like a step function than a linear function, so the normality assumption is doubtful. It is then safer to use Spearman's correlation test, which does not assume normality. In this case, the null hypothesis is that the correlation coefficient is equal to 0, i.e. there is no correlation. Since our p-value for the Spearman test is much lower than 0.05, we reject the null hypothesis in favor of the alternative, that there is a significant correlation between the two samples.
